{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from progress.bar import Bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNetwork:\n",
    "    def __init__(self, layers: list, activate_function='sigmoid', cost_function='square_error'):\n",
    "        self.layers = layers\n",
    "        self.network = None\n",
    "        \n",
    "        if activate_function == 'sigmoid':\n",
    "            self._activate_function = lambda x: 1/(1 + np.exp(-x))\n",
    "            self._derivative_activate_function = lambda x: x * (1.0 - x)\n",
    "            \n",
    "        if cost_function == 'square_error':\n",
    "            self._cost_function = lambda x, y: 1/2 * (x - y)**2\n",
    "            self._derivative_cost_function = lambda x, y: x - y\n",
    "        \n",
    "        self._initialize_network()\n",
    "    \n",
    "    def _initialize_network(self):\n",
    "        self.network = list()\n",
    "        for i in range(1, len(self.layers)):\n",
    "            layer = np.random.rand(self.layers[i], self.layers[i-1])\n",
    "            self.network.append({\"weights\": layer, \"forward\": None, \"deltas\": None})\n",
    "            \n",
    "    def _forward_propagation(self, inputs: np.array):\n",
    "        for layer in self.network:\n",
    "            weigths = layer['weights']\n",
    "            inputs = self._activate_function(weigths @ inputs)\n",
    "            layer['forward'] = inputs\n",
    "        return inputs\n",
    "            \n",
    "    def _back_propagation(self, y):\n",
    "        for index in reversed(range(len(self.network))):\n",
    "            layer = self.network[index]\n",
    "            if index == len(self.network)-1:\n",
    "                layer['deltas'] = (y - layer['forward']) * self._derivative_activate_function(layer['forward'])\n",
    "            else:\n",
    "                next_layer = self.network[index+1]\n",
    "                layer['deltas'] = self._derivative_activate_function(layer['forward']) * (next_layer['deltas'] @ next_layer['weights'])        \n",
    "    \n",
    "    def _update_weights(self, inputs, lr):\n",
    "        for index, layer in enumerate(self.network):\n",
    "            if index == 0:\n",
    "                x0, x1 = np.meshgrid(inputs, layer['deltas'])\n",
    "                dw = lr * (x0 * x1)\n",
    "            else:\n",
    "                x0, x1 = np.meshgrid(self.network[index-1]['forward'], layer['deltas'])\n",
    "                dw = lr * (x0 * x1)\n",
    "            \n",
    "            layer['weights'] += dw\n",
    "    \n",
    "    def fit(self, X, y, n_epoch=10000, lr=0.01, verbose_epoch=500):\n",
    "        print(\"learning rate = %.3f\" % lr)\n",
    "        for epoch in range(n_epoch):\n",
    "            for x_, y_ in zip(X, y):\n",
    "                self._forward_propagation(x_)                \n",
    "                self._back_propagation(y_)\n",
    "                self._update_weights(x_, lr)\n",
    "                \n",
    "            if epoch % verbose_epoch == 0:\n",
    "                error = np.sqrt(mean_squared_error(y, self.predict(X)))\n",
    "                print('epoch=%d, error=%.3f' % (epoch, error))\n",
    "            elif epoch == n_epoch-1:\n",
    "                print('epoch=%d, error=%.3f' % (epoch+1, error))\n",
    "            \n",
    "    def predict(self, inputs: np.array, around=None):\n",
    "        output = []\n",
    "        for x in inputs:\n",
    "            output.append(self._forward_propagation(x))\n",
    "        \n",
    "        output = np.array(output)\n",
    "        if around is not None:\n",
    "            output = np.around(output, decimals=around)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 3x3 counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 1],\n",
    "    [0, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 0.200\n",
      "epoch=0, error=0.634\n",
      "epoch=500, error=0.416\n",
      "epoch=1000, error=0.370\n",
      "epoch=1500, error=0.330\n",
      "epoch=2000, error=0.234\n",
      "epoch=2500, error=0.189\n",
      "epoch=3000, error=0.103\n",
      "epoch=3500, error=0.067\n",
      "epoch=4000, error=0.053\n",
      "epoch=4500, error=0.045\n",
      "epoch=5000, error=0.040\n",
      "epoch=5500, error=0.036\n",
      "epoch=6000, error=0.033\n",
      "epoch=6500, error=0.031\n",
      "epoch=7000, error=0.029\n",
      "epoch=7500, error=0.027\n",
      "epoch=8000, error=0.026\n",
      "epoch=8500, error=0.025\n",
      "epoch=9000, error=0.024\n",
      "epoch=9500, error=0.023\n",
      "epoch=10000, error=0.023\n"
     ]
    }
   ],
   "source": [
    "nn = NNetwork([3, 5, 5, 3])\n",
    "nn.fit(X, y, lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 1.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(X[:], around=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weights': array([[ 2.74118129,  2.73384604,  0.3540177 ],\n",
       "         [-0.53212007,  4.32525144, -4.25535499],\n",
       "         [-5.51549648,  3.98401597,  2.79786713],\n",
       "         [ 4.22384839, -2.12024867, -0.27300663],\n",
       "         [-0.29344499, -2.9360716 ,  6.01924118]]),\n",
       "  'forward': array([0.99706775, 0.386581  , 0.78011094, 0.86181968, 0.94211475]),\n",
       "  'deltas': array([-3.59995248e-06, -8.61359989e-04,  1.22717607e-04,  1.77568065e-04,\n",
       "          1.00291584e-04])},\n",
       " {'weights': array([[ 3.55962736,  5.34345808, -1.03172369, -4.70154527, -2.23766325],\n",
       "         [ 1.03893756, -2.54946485, -1.4206578 , -0.06823608,  5.97197653],\n",
       "         [ 1.61234503, -9.03820386, -0.51431573, -3.2197254 ,  4.30893546],\n",
       "         [-1.70586728, -0.19936624,  8.99929047, -2.4052372 ,  1.33087186],\n",
       "         [-2.07169691,  6.35313427, -0.06771379,  1.13671705, -5.24078292]]),\n",
       "  'forward': array([0.20591524, 0.98911607, 0.26835625, 0.98814919, 0.02607995]),\n",
       "  'deltas': array([-4.20016487e-04,  1.58552435e-06,  9.35009114e-05,  3.63096482e-05,\n",
       "         -8.36794922e-05])},\n",
       " {'weights': array([[ 9.12001076,  2.32678431,  3.11819816, -9.24401264, -4.2422077 ],\n",
       "         [-2.88571599, -6.20507441, 11.07553873, -1.01516732,  7.93497687],\n",
       "         [ 2.94199785,  0.12538016, -6.59555728, -3.19902917,  9.50624034]]),\n",
       "  'forward': array([0.01436036, 0.01039778, 0.01883187]),\n",
       "  'deltas': array([-0.00020326, -0.00010699, -0.00034796])}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 4x4 counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 1, 0, 1],\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 1, 1, 1],\n",
    "    [1, 0, 0, 0],\n",
    "    [1, 0, 0, 1],\n",
    "    [1, 0, 1, 0],\n",
    "    [1, 0, 1, 1],\n",
    "    [1, 1, 0, 0],\n",
    "    [1, 1, 0, 1],\n",
    "    [1, 1, 1, 0],\n",
    "    [1, 1, 1, 1]\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 1, 0, 1],\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 1, 1, 1],\n",
    "    [1, 0, 0, 0],\n",
    "    [1, 0, 0, 1],\n",
    "    [1, 0, 1, 0],\n",
    "    [1, 0, 1, 1],\n",
    "    [1, 1, 0, 0],\n",
    "    [1, 1, 0, 1],\n",
    "    [1, 1, 1, 0],\n",
    "    [1, 1, 1, 1],\n",
    "    [0, 0, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 0.200\n",
      "epoch=0, error=0.627\n",
      "epoch=500, error=0.377\n",
      "epoch=1000, error=0.234\n",
      "epoch=1500, error=0.125\n",
      "epoch=2000, error=0.107\n",
      "epoch=2500, error=0.100\n",
      "epoch=3000, error=0.097\n",
      "epoch=3500, error=0.095\n",
      "epoch=4000, error=0.094\n",
      "epoch=4500, error=0.093\n",
      "epoch=5000, error=0.092\n",
      "epoch=5500, error=0.092\n",
      "epoch=6000, error=0.091\n",
      "epoch=6500, error=0.091\n",
      "epoch=7000, error=0.090\n",
      "epoch=7500, error=0.066\n",
      "epoch=8000, error=0.045\n",
      "epoch=8500, error=0.037\n",
      "epoch=9000, error=0.032\n",
      "epoch=9500, error=0.029\n",
      "epoch=10000, error=0.027\n",
      "epoch=10500, error=0.025\n",
      "epoch=11000, error=0.023\n",
      "epoch=11500, error=0.022\n",
      "epoch=12000, error=0.021\n",
      "epoch=12500, error=0.020\n",
      "epoch=13000, error=0.019\n",
      "epoch=13500, error=0.019\n",
      "epoch=14000, error=0.018\n",
      "epoch=14500, error=0.017\n",
      "epoch=15000, error=0.017\n",
      "epoch=15500, error=0.016\n",
      "epoch=16000, error=0.016\n",
      "epoch=16500, error=0.016\n",
      "epoch=17000, error=0.015\n",
      "epoch=17500, error=0.015\n",
      "epoch=18000, error=0.015\n",
      "epoch=18500, error=0.014\n",
      "epoch=19000, error=0.014\n",
      "epoch=19500, error=0.014\n",
      "epoch=20000, error=0.014\n"
     ]
    }
   ],
   "source": [
    "nn = NNetwork([4, 6, 6, 4])\n",
    "nn.fit(X, y, n_epoch=20000, lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [0., 1., 1., 0.],\n",
       "       [0., 1., 1., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 1.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 1.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(X[:], around=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New realization with the grid search method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, numbers):\n",
    "        self.numbers = numbers\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.numbers.__repr__()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.numbers.__str__()\n",
    "\n",
    "class NNetwork:\n",
    "    def __init__(self, layer: Layer, activate_function='sigmoid', cost_function='squared_error'):\n",
    "        self.layers = layer.numbers\n",
    "        self.network = None\n",
    "\n",
    "        self.alpha = 0.3\n",
    "\n",
    "        if activate_function == 'sigmoid':\n",
    "            self._activate_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "            self._derivative_activate_function = lambda x: x * (1.0 - x)\n",
    "        elif activate_function == 'elu':\n",
    "            self._activate_function = lambda z: np.vstack(\n",
    "                list(map(lambda z: z if z >= 0 else self.alpha * (np.exp(z) - 1), z)))\n",
    "            self._derivative_activate_function = lambda z: np.vstack(\n",
    "                list(map(lambda z: 1 if z > 0 else self.alpha * np.exp(z), z)))\n",
    "\n",
    "        if cost_function == 'squared_error':\n",
    "            self._cost_function = lambda x, y: 1 / 2 * (x - y) ** 2\n",
    "            self._derivative_cost_function = lambda x, y: x - y\n",
    "\n",
    "        self._initialize_network()\n",
    "\n",
    "    def _initialize_network(self):\n",
    "        self.network = list()\n",
    "        for i in range(1, len(self.layers)):\n",
    "            layer = np.random.randn(self.layers[i], self.layers[i - 1]) * np.sqrt(2/self.layers[i-1])\n",
    "            self.network.append({\"weights\": layer, \"forward\": None, \"deltas\": None})\n",
    "\n",
    "    def _forward_propagation(self, inputs: np.array):\n",
    "        for layer in self.network:\n",
    "            weigths = layer['weights']\n",
    "            inputs = self._activate_function(weigths @ inputs)\n",
    "            layer['forward'] = inputs\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def _back_propagation(self, y):\n",
    "        for index in reversed(range(len(self.network))):\n",
    "            layer = self.network[index]\n",
    "            if index == len(self.network) - 1:\n",
    "                layer['deltas'] = (y - layer['forward']) * self._derivative_activate_function(layer['forward'])\n",
    "            else:\n",
    "                next_layer = self.network[index + 1]\n",
    "                layer['deltas'] = self._derivative_activate_function(layer['forward']).T * (\n",
    "                            next_layer['deltas'] @ next_layer['weights'])\n",
    "\n",
    "    def _update_weights(self, inputs, lr):\n",
    "        for index, layer in enumerate(self.network):\n",
    "            if index == 0:\n",
    "                x0, x1 = np.meshgrid(inputs, layer['deltas'])\n",
    "                dw = lr * (x0 * x1)\n",
    "            else:\n",
    "                x0, x1 = np.meshgrid(self.network[index - 1]['forward'], layer['deltas'])\n",
    "                dw = lr * (x0 * x1)\n",
    "\n",
    "            layer['weights'] += dw\n",
    "\n",
    "    def fit(self, X, y, n_epoch=10000, lr=0.01, verbose=True, verbose_epoch=500, flatten=False, scaling=True):\n",
    "        if verbose:\n",
    "            print(\"learning rate = %.3f\" % lr)\n",
    "        for epoch in range(n_epoch):\n",
    "            for x_, y_ in zip(X, y):\n",
    "                if flatten:\n",
    "                    x_ = x_.reshape(-1, 1)\n",
    "                if scaling:\n",
    "                    x_ = StandardScaler().fit_transform(x_)\n",
    "                self._forward_propagation(x_)\n",
    "                self._back_propagation(y_)\n",
    "                self._update_weights(x_, lr)\n",
    "\n",
    "            if verbose:\n",
    "                if epoch % verbose_epoch == 0:\n",
    "                    error = np.sqrt(mean_squared_error(y, self.predict(X, flatten=flatten)))\n",
    "                    print('epoch=%d, error=%.3f' % (epoch, error))\n",
    "                elif epoch == n_epoch - 1:\n",
    "                    print('epoch=%d, error=%.3f' % (epoch + 1, error))\n",
    "\n",
    "    def predict(self, inputs: np.array, around=None, flatten=True):\n",
    "        output = []\n",
    "        for x in inputs:\n",
    "            if flatten:\n",
    "                x = x.reshape(-1, 1)\n",
    "            output.append(self._forward_propagation(x))\n",
    "\n",
    "        output = np.array(output)\n",
    "        if around is not None:\n",
    "            output = np.around(output, decimals=around)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = [\n",
    "    {'layers': [Layer([4, 8, 8, 4]), Layer([4, 9, 9, 4]), Layer([4, 10, 10, 4])], 'activate_function': ['sigmoid'], \n",
    "     'cost_function': ['squared_error'], 'n_epoch': [35000], 'lr': [0.27, 0.33]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearch:\n",
    "    def __init__(self, grid_params):\n",
    "        self.grid_params = grid_params\n",
    "        self.best_estimator = None\n",
    "        self.best_params = None\n",
    "        \n",
    "    def fit(self, X, y, split_data=True):\n",
    "        X_train, X_test, y_train, y_test = X, X, y, y\n",
    "        if split_data:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "        \n",
    "        min_error = np.inf\n",
    "        \n",
    "        for gp in self.grid_params:            \n",
    "            grid_params = np.array(np.meshgrid(*gp.values())).T.reshape(-1, len(gp))\n",
    "            \n",
    "            for params in grid_params:                \n",
    "                params = {key: value for key, value in zip(gp.keys(), params)}\n",
    "                print(\"Parameters: \")\n",
    "                for key, value in params.items():\n",
    "                    print(f\"{key}: {value}\")\n",
    "                \n",
    "                estimator = NNetwork(layer=params['layers'], activate_function=params['activate_function'], cost_function=params['cost_function'])\n",
    "                estimator.fit(X_train, y_train, n_epoch=params['n_epoch'], lr=params['lr'], verbose=False)\n",
    "                \n",
    "                error = np.sqrt(mean_squared_error(y_test, estimator.predict(X_test)))\n",
    "                print(\"Loss: \", error, '\\n')\n",
    "                if error < min_error:\n",
    "                    self.best_estimator = estimator\n",
    "                    self.best_params = params\n",
    "                    self.best_loss = error\n",
    "                    min_error = error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-da9dffbdf65f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "gs = GridSearch(grid_params)\n",
    "gs.fit(X, y, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004043618179800168"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: \n",
      "layers: [4, 9, 9, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.27\n",
      "Loss:  0.004527102163320592 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 10, 10, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.27\n",
      "Loss:  0.004982682583380623 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 11, 11, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.27\n",
      "Loss:  0.005808453712347198 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 12, 12, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.27\n",
      "Loss:  0.004955974493372239 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 9, 9, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.33\n",
      "Loss:  0.003697313854540265 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 10, 10, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.33\n",
      "Loss:  0.004414185550958853 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 11, 11, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.33\n",
      "Loss:  0.004711139407623769 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 12, 12, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.33\n",
      "Loss:  0.004507448015667686 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 9, 9, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.36\n",
      "Loss:  0.0036405296693244912 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 10, 10, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.36\n",
      "Loss:  0.0036231835245395033 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 11, 11, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.36\n",
      "Loss:  0.004557529035800173 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 12, 12, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.36\n",
      "Loss:  0.0033906736507883536 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 9, 9, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.4\n",
      "Loss:  0.004320750392092462 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 10, 10, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.4\n",
      "Loss:  0.004047232207355289 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 11, 11, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.4\n",
      "Loss:  0.00451745655884719 \n",
      "\n",
      "Parameters: \n",
      "layers: [4, 12, 12, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 35000\n",
      "lr: 0.4\n",
      "Loss:  0.0037729872002822498 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_params = [\n",
    "    {'layers': [Layer([4, 9, 9, 4]), Layer([4, 10, 10, 4]), Layer([4, 11, 11, 4]), Layer([4, 12, 12, 4])], 'activate_function': ['sigmoid'], \n",
    "     'cost_function': ['squared_error'], 'n_epoch': [35000], 'lr': [0.27, 0.33, 0.36, 0.4]}\n",
    "]\n",
    "\n",
    "gs = GridSearch(grid_params)\n",
    "gs.fit(X, y, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: \n",
      "layers: [4, 16, 16, 4]\n",
      "activate_function: sigmoid\n",
      "cost_function: squared_error\n",
      "n_epoch: 100000\n",
      "lr: 1\n",
      "Loss:  0.001086347569079432 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_params = [\n",
    "    {'layers': [Layer([4, 16, 16, 4])], 'activate_function': ['sigmoid'], \n",
    "     'cost_function': ['squared_error'], 'n_epoch': [100000], 'lr': [1]}\n",
    "]\n",
    "\n",
    "gs = GridSearch(grid_params)\n",
    "gs.fit(X, y, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 1.],\n",
       "       [0., 1., 1., 0.],\n",
       "       [0., 1., 1., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 1.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 1.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 1.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator.predict(X, around = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: build a neural network that can to recognize even digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_image(images, limit_per_row=5):\n",
    "    for index, image in enumerate(images):\n",
    "        image = image.reshape(28, 28)\n",
    "        n_rows = (len(images)-1) // limit_per_row + 1\n",
    "        plt.subplot(n_rows, limit_per_row, index+1)\n",
    "        plt.imshow(image, cmap=mpl.cm.binary, interpolation='nearest')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "y_train_even = (y_train % 2 == 0).astype(int)\n",
    "y_test_even = (y_test % 2 == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_image(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, numbers):\n",
    "        self.numbers = numbers\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.numbers.__repr__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.numbers.__str__()\n",
    "\n",
    "\n",
    "class NNetwork:\n",
    "    def __init__(self, layer: Layer, activate_functions: list, alpha=0.3, cost_function='squared_error'):\n",
    "        self.layers = layer.numbers\n",
    "        self.activate_functions = activate_functions\n",
    "        self.network = None\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "        if cost_function == 'squared_error':\n",
    "            self._cost_function = lambda x, y: 1 / 2 * (x - y) ** 2\n",
    "            self._derivative_cost_function = lambda x, y: x - y\n",
    "\n",
    "        self._initialize_network()\n",
    "\n",
    "    def _get_activate_functions(self, name):\n",
    "        if name == 'sigmoid':\n",
    "            activate_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "            derivative_activate_function = lambda x: x * (1.0 - x)\n",
    "        elif name == 'elu':\n",
    "            activate_function = lambda z: np.vstack(\n",
    "                list(map(lambda z: z if z >= 0 else self.alpha * (np.exp(z) - 1), z)))\n",
    "            derivative_activate_function = lambda z: np.vstack(\n",
    "                list(map(lambda z: 1 if z > 0 else self.alpha * np.exp(z), z)))\n",
    "\n",
    "        return activate_function, derivative_activate_function\n",
    "\n",
    "    def _initialize_network(self):\n",
    "        self.network = list()\n",
    "        for i, activate_name in zip(range(1, len(self.layers)), self.activate_functions):\n",
    "            activate_func, derivative_func = self._get_activate_functions(activate_name)\n",
    "            weights = np.random.randn(self.layers[i], self.layers[i - 1]) * np.sqrt(2 / self.layers[i - 1])\n",
    "            self.network.append({\"weights\": weights, \"forward\": None,\n",
    "                                 \"activate\": activate_func, \"derivative\": derivative_func, \"deltas\": None})\n",
    "\n",
    "    def _forward_propagation(self, inputs: np.array):\n",
    "        for layer in self.network:\n",
    "            weights = layer['weights']\n",
    "            activate_func = layer['activate']\n",
    "            inputs = activate_func(weights @ inputs)\n",
    "            layer['forward'] = inputs\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def _back_propagation(self, y):\n",
    "        for index in reversed(range(len(self.network))):\n",
    "            layer = self.network[index]\n",
    "            derivative = layer['derivative']\n",
    "            if index == len(self.network) - 1:\n",
    "                layer['deltas'] = (y - layer['forward']) * derivative(layer['forward'])\n",
    "            else:\n",
    "                next_layer = self.network[index + 1]\n",
    "                layer['deltas'] = derivative(layer['forward']).T * (\n",
    "                        next_layer['deltas'] @ next_layer['weights'])\n",
    "\n",
    "    def _update_weights(self, inputs, lr):\n",
    "        for index, layer in enumerate(self.network):\n",
    "            if index == 0:\n",
    "                x0, x1 = np.meshgrid(inputs, layer['deltas'])\n",
    "                dw = lr * (x0 * x1)\n",
    "            else:\n",
    "                x0, x1 = np.meshgrid(self.network[index - 1]['forward'], layer['deltas'])\n",
    "                dw = lr * (x0 * x1)\n",
    "\n",
    "            layer['weights'] += dw\n",
    "\n",
    "    def fit(self, X, y, n_epoch=10000, lr=0.01, batch_size=30, validate_batch_size=10000, verbose=True, verbose_epoch=500, flatten=False, scaling=True):\n",
    "        if verbose:\n",
    "            print(\"learning rate = %.6f\" % lr)\n",
    "        for epoch in range(n_epoch):\n",
    "            indexes = np.random.randint(0, len(X), size=batch_size)\n",
    "            X_sample, y_sample = X[indexes], y[indexes]\n",
    "            for x_, y_ in zip(X_sample, y_sample):\n",
    "                if flatten:\n",
    "                    x_ = x_.reshape(-1, 1)\n",
    "                if scaling:\n",
    "                    x_ = StandardScaler().fit_transform(x_)\n",
    "                self._forward_propagation(x_)\n",
    "                self._back_propagation(y_)\n",
    "                self._update_weights(x_, lr)\n",
    "\n",
    "            if verbose:\n",
    "                if epoch % verbose_epoch == 0:\n",
    "                    indexes = np.random.randint(0, len(X), size=validate_batch_size)\n",
    "                    error = np.sqrt(mean_squared_error(y[indexes], self.predict(X[indexes], flatten=flatten)))\n",
    "                    print('epoch=%d, error=%.3f' % (epoch, error))\n",
    "                elif epoch == n_epoch - 1:\n",
    "                    indexes = np.random.randint(0, len(X), size=validate_batch_size)\n",
    "                    error = np.sqrt(mean_squared_error(y[indexes], self.predict(X[indexes], flatten=flatten)))\n",
    "                    print('epoch=%d, error=%.3f' % (epoch + 1, error))\n",
    "\n",
    "    def predict(self, inputs: np.array, around=None, flatten=True):\n",
    "        output = []\n",
    "        for x in inputs:\n",
    "            if flatten:\n",
    "                x = x.reshape(-1, 1)\n",
    "            output.append(self._forward_propagation(x))\n",
    "\n",
    "        output = np.vstack(output)\n",
    "        if around is not None:\n",
    "            output = np.around(output, decimals=around)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 0.001000\n",
      "epoch=0, error=0.633\n",
      "epoch=10, error=0.443\n",
      "epoch=20, error=0.417\n",
      "epoch=30, error=0.393\n",
      "epoch=40, error=0.380\n",
      "epoch=50, error=0.340\n",
      "epoch=60, error=0.328\n",
      "epoch=70, error=0.326\n",
      "epoch=80, error=0.345\n",
      "epoch=90, error=0.341\n",
      "epoch=100, error=0.275\n"
     ]
    }
   ],
   "source": [
    "NN = NNetwork(Layer([784, 300, 100, 50, 1]), ['elu', 'elu', 'elu', 'sigmoid'])\n",
    "NN.fit(X_train, y_train_even, n_epoch=100, batch_size=100, validate_batch_size=1000, flatten=True, verbose_epoch=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_image(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.predict(X_train[:10], around=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_even[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = NN.predict(X_test[:5000], around=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8854"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_even[:5000], y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
